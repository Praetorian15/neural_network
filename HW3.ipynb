{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "  1. Постройте нейронную сеть(берем простую линейную сеть, которую разбирали на уроке: меняем число слоев, число нейронов , типы активации, тип оптимизатора)  на датасет from sklearn.datasets import load_boston. \n",
    "  2. Измените функцию потерь и метрику для этой задачи. Постройте 10-15 вариантов и сведите результаты их работы в таблицу  Опишите, какого результата вы добились от нейросети? Что помогло вам улучшить ее точность?\n",
    "\n",
    "  3. Поработайте с документацией TensorFlow 2. Найти 2-3 полезные команды TensorFlow, не разобранные на уроке (полезные для Вас)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2752,
     "status": "ok",
     "timestamp": 1649786870610,
     "user": {
      "displayName": "Mariia Korliakova",
      "userId": "14165537686129864864"
     },
     "user_tz": -180
    },
    "id": "qBUSq3dWHUjF",
    "outputId": "99898920-7951-489c-ce5a-5cf807327081"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import boston_housing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(train_data,train_labels),(test_data,test_labels)=boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.55369355, -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "        -3.48459553,  2.25092074],\n",
       "       [-0.39242675, -0.48361547, -0.16087773, ..., -0.30759583,\n",
       "         0.42733126,  0.47880119],\n",
       "       [-0.39982927, -0.48361547, -0.86940196, ...,  0.78447637,\n",
       "         0.44807713, -0.41415936],\n",
       "       ...,\n",
       "       [-0.20709507, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "         0.37051949, -1.49344089],\n",
       "       [-0.36698601, -0.48361547, -0.72093526, ..., -0.48960787,\n",
       "         0.39275481, -0.41829982],\n",
       "       [-0.0889679 , -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -1.21946544, -0.40449827]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Нормализация.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(train_data)\n",
    "scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 26.7792 - mae: 3.7465\n",
      "4/4 [==============================] - 0s 998us/step - loss: 51.1990 - mae: 5.7418\n",
      "4/4 [==============================] - 0s 998us/step - loss: 29.0830 - mae: 3.8666\n",
      "4/4 [==============================] - 0s 997us/step - loss: 42.3675 - mae: 4.5978\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 26.6179 - mae: 3.7406\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 31.4849 - mae: 4.0069\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 44.2872 - mae: 4.7397\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 27.9282 - mae: 3.7891\n",
      "4/4 [==============================] - 0s 987us/step - loss: 28.9714 - mae: 3.6345\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 33.3446 - mae: 3.9466\n",
      "4/4 [==============================] - 0s 998us/step - loss: 38.7279 - mae: 4.4692\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 30.3820 - mae: 3.5418\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 42.1326 - mae: 4.7079\n",
      "4/4 [==============================] - 0s 998us/step - loss: 26.8910 - mae: 3.6575\n",
      "4/4 [==============================] - 0s 998us/step - loss: 27.2809 - mae: 3.4106\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 28.4160 - mae: 3.8480\n",
      "4/4 [==============================] - 0s 998us/step - loss: 27.4342 - mae: 3.5255\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 29.5108 - mae: 3.4089\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 24.9035 - mae: 3.3707\n",
      "4/4 [==============================] - 0s 998us/step - loss: 58.7813 - mae: 6.3531\n",
      "4/4 [==============================] - 0s 998us/step - loss: 27.4872 - mae: 3.5841\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 24.6559 - mae: 3.6235\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 31.9362 - mae: 3.7980\n",
      "4/4 [==============================] - 0s 998us/step - loss: 26.8833 - mae: 3.4003\n",
      "4/4 [==============================] - 0s 997us/step - loss: 25.3245 - mae: 3.4910\n",
      "4/4 [==============================] - 0s 998us/step - loss: 31.3541 - mae: 3.6850\n",
      "4/4 [==============================] - 0s 997us/step - loss: 29.1257 - mae: 3.4572\n",
      "4/4 [==============================] - 0s 998us/step - loss: 25.5665 - mae: 3.5618\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 34.3995 - mae: 4.1139\n",
      "4/4 [==============================] - 0s 997us/step - loss: 25.7764 - mae: 3.5747\n",
      "4/4 [==============================] - 0s 998us/step - loss: 35.7654 - mae: 4.5446\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 31.3496 - mae: 4.1852\n",
      "4/4 [==============================] - 0s 998us/step - loss: 31.9119 - mae: 4.1163\n",
      "4/4 [==============================] - 0s 998us/step - loss: 32.3631 - mae: 4.0062\n",
      "4/4 [==============================] - 0s 998us/step - loss: 26.4938 - mae: 3.5297\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 29.7444 - mae: 3.6088\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 23.9073 - mae: 3.2822\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 33.6255 - mae: 4.3242\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 36.9341 - mae: 4.1277\n",
      "4/4 [==============================] - 0s 998us/step - loss: 27.8452 - mae: 3.5469\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 28.2110 - mae: 3.3671\n",
      "4/4 [==============================] - 0s 998us/step - loss: 32.5917 - mae: 3.5039\n",
      "4/4 [==============================] - 0s 998us/step - loss: 27.5738 - mae: 3.5695\n",
      "4/4 [==============================] - 0s 998us/step - loss: 31.4202 - mae: 3.4969\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 35.6717 - mae: 3.7746\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 43.9747 - mae: 5.2089\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 25.1274 - mae: 3.4582\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 29.0923 - mae: 3.6030\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 28.2849 - mae: 3.2116\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 27.9967 - mae: 3.7280\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 26.2463 - mae: 3.2011\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 27.6905 - mae: 3.3405\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 30.3141 - mae: 3.4833\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 27.2888 - mae: 3.3153\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 26.1883 - mae: 3.4693\n",
      "4/4 [==============================] - 0s 998us/step - loss: 35.3849 - mae: 4.4977\n",
      "4/4 [==============================] - 0s 998us/step - loss: 24.8001 - mae: 3.2139\n",
      "4/4 [==============================] - 0s 997us/step - loss: 32.2641 - mae: 3.9432\n",
      "4/4 [==============================] - 0s 998us/step - loss: 31.3719 - mae: 3.8662\n",
      "4/4 [==============================] - 0s 998us/step - loss: 36.2603 - mae: 4.2378\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 32.3301 - mae: 4.0168\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 31.0896 - mae: 3.7873\n",
      "4/4 [==============================] - 0s 998us/step - loss: 37.4714 - mae: 4.3214\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 26.7377 - mae: 3.4491\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 30.9606 - mae: 3.8116\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 29.4461 - mae: 3.4224\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 33.4380 - mae: 4.3061\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 38.6236 - mae: 4.5396\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 43.5541 - mae: 5.0386\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 27.3388 - mae: 3.6005\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 29.5735 - mae: 3.4913\n",
      "4/4 [==============================] - 0s 998us/step - loss: 29.1249 - mae: 3.3422\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 22.1326 - mae: 3.1767\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 25.7987 - mae: 3.4353\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 25.8368 - mae: 3.4474\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 25.6240 - mae: 3.2902\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 33.7059 - mae: 3.9100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 30.2311 - mae: 3.5646\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 27.9394 - mae: 3.3048\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 29.9538 - mae: 3.5757\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 25.0729 - mae: 3.0331\n"
     ]
    }
   ],
   "source": [
    "# Попробуем разные варианты\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "epoch = np.arange(epochs+1)\n",
    "\n",
    "mae_train = {}\n",
    "mae_test = {}\n",
    "\n",
    "for layers in range(2, 5):\n",
    "    for i in [64, 128, 256]:\n",
    "        for activation in ['relu', 'tanh', 'sigmoid']:\n",
    "\n",
    "            # создаем рабочую модель model \n",
    "            model = Sequential(name='model')\n",
    "            for k in range(2, layers+1):\n",
    "                model.add(Dense(  i, activation=activation))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            \n",
    "            for opt in ['adam', 'rmsprop', 'nadam']:\n",
    "\n",
    "                # компилируем model \n",
    "                model.compile(\n",
    "                    optimizer=opt,\n",
    "                    loss='mse',\n",
    "                    metrics=['mae'],\n",
    "                    )\n",
    "\n",
    "                # проводим обучение модели \n",
    "                hh_train = model.fit(\n",
    "                              train_data,\n",
    "                              train_labels,\n",
    "                              epochs=epochs,\n",
    "                              batch_size=128, verbose = 0\n",
    "                              )\n",
    "                # вычисляем ошибку для model\n",
    "                hh_test = model.evaluate(\n",
    "                              test_data,\n",
    "                              test_labels\n",
    "                              )\n",
    "\n",
    "                mae_train[str(k) + '_' + str(i) + '_' + activation + '_' + opt] = round(hh_train.history['mae'][-1], 3)\n",
    "                mae_test[str(k) + '_' + str(i) + '_' + activation + '_' + opt] = round(hh_test[1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_256_relu_nadam\n",
      "0.998\n"
     ]
    }
   ],
   "source": [
    "print(min(mae_train, key=mae_train.get))\n",
    "print(min(mae_train.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_256_sigmoid_nadam\n",
      "3.033\n"
     ]
    }
   ],
   "source": [
    "print(min(mae_test, key=mae_test.get))\n",
    "print(min(mae_test.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данной задачи регрессии лучше себя проявила сигмоида, оптимизатор - надам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name='model')\n",
    "model.add(Dense(  256, activation='sigmoid'))\n",
    "model.add(Dense(  256, activation='sigmoid'))\n",
    "model.add(Dense(  256, activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "            \n",
    "model.compile(\n",
    "            optimizer='nadam',\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "            )\n",
    "\n",
    "                \n",
    "hh_train = model.fit(\n",
    "              train_data,\n",
    "              train_labels,\n",
    "              epochs=1500,\n",
    "              batch_size=128, verbose = 0\n",
    "              )\n",
    "\n",
    "y_pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3150420862085683"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6482449894553013"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменяя функцию активации, оптимизатор, количество слоев и нейронов в них я пытался найти наиболее оптимальное сочетание для данной задачи, к сожадению, результаты работы сети оставляют желать лучшего, так как датасет слишком мал для нормального обучения."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "metodich3_colab_29_12.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
